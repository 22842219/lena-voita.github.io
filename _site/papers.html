<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Publications</title>

    <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="css/bootstrap-glyphicons.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- MathJax -->
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Publications</title>
    <meta name="description" content="Here you will find details about my work.
">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://localhost:4000/papers.html">

    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>


</head>

  <body>
    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Lena Voita</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/posts.html">Blog</a>
          
        
          
          <a class="page-link" href="/papers.html">Publications</a>
          
        
          
          <a class="page-link" href="/teaching.html">Teaching & Supervising</a>
          
        
<!--        <a href="">
            <img src="image/UoS.ico" alt="DCS">
        </a>-->
      </div>
    </nav>

  </div>

</header>

    <!-- JavaScript plugins (requires jQuery) -->
    <script src="http://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed --!>
    <script src="js/bootstrap.min.js"></script>

    <div class="page-content">
      <div class="row">
        <div class="wrapper">
          
<div class="media">
  <a class="pull-left thumbnail">
    <img src="/img/paper/acl19_heads-min.png" alt="" style="max-width:90px; height:auto;" />
  </a>
  <div class="media-body">
    <!-- citation -->
    
    <strong>Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned</strong><br />
    Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich and Ivan Titov.
    
        In
        
          <i>Proceedings of ACL</i>,
        
      
    2019.
    
    <br />

    <!-- abstract -->
    
      <a data-toggle="modal" href="#abstractacl19_heads-min.png" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractacl19_heads-min.png" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned</h4>
            </div>
            <div class="modal-body">
              <p>Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads in the encoder to the overall performance of the model and analyze the roles played by them. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.</p>

            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
    

    <!-- bibtex -->
    
      <!-- Modal -->
      <div class="modal fade" id="bibtexacl19_heads-min.png" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Bibtex | Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned</h4>
            </div>
            <div class="modal-body">
              <pre>
}
</pre>
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
      <a data-toggle="modal" href="#bibtexacl19_heads-min.png" class="label label-default">Bibtex</a>&nbsp;
    

    <!-- resources -->
    <!-- draft/slides/poster/talk -->

    
    
    
    <a href="//arxiv.org/abs/1905.09418" class="label label-info">arXiv</a>
    
    
    

    

    

    

    <!-- code and data -->
    

    

    <!-- amendments -->

    
  </div>
</div>

<div class="media">
  <a class="pull-left thumbnail">
    <img src="/img/paper/acl19_ctx.png" alt="" style="max-width:90px; height:auto;" />
  </a>
  <div class="media-body">
    <!-- citation -->
    
    <strong>When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</strong><br />
    Elena Voita, Rico Sennrich and Ivan Titov.
    
        In
        
          <i>Proceedings of ACL</i>,
        
      
    2019.
    
    <br />

    <!-- abstract -->
    
      <a data-toggle="modal" href="#abstractacl19_ctx.png" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractacl19_ctx.png" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</h4>
            </div>
            <div class="modal-body">
              <p>Though machine translation errors caused by the lack of context beyond one sentence have long been acknowledged, the development of context-aware NMT systems is hampered by several problems. Firstly, standard metrics are not sensitive to improvements in consistency in document-level translations. Secondly, previous work on context-aware NMT assumed that the sentence-aligned parallel data consisted of complete documents while in most practical scenarios such document-level data constitutes only a fraction of the available parallel data. To address the first issue, we perform a human study on an English-Russian subtitles dataset and identify deixis, ellipsis and lexical cohesion as three main sources of inconsistency. We then create test sets targeting these phenomena. To address the second shortcoming, we consider a set-up in which a much larger amount of sentence-level data is available compared to that aligned at the document level. We introduce a model that is suitable for this scenario and demonstrate major gains over a context-agnostic baseline on our new benchmarks without sacrificing performance as measured with BLEU.</p>

            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
    

    <!-- bibtex -->
    
      <!-- Modal -->
      <div class="modal fade" id="bibtexacl19_ctx.png" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Bibtex | When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</h4>
            </div>
            <div class="modal-body">
              <pre>
}
</pre>
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
      <a data-toggle="modal" href="#bibtexacl19_ctx.png" class="label label-default">Bibtex</a>&nbsp;
    

    <!-- resources -->
    <!-- draft/slides/poster/talk -->

    
    
    
    <a href="//arxiv.org/abs/1905.05979" class="label label-info">arXiv</a>
    
    
    

    

    

    

    <!-- code and data -->
    

    

    <!-- amendments -->

    
  </div>
</div>

<div class="media">
  <a class="pull-left thumbnail" href="//aclweb.org/anthology/P18-1117/">
    <img src="/img/paper/ctx_anaphora.png" alt="" style="max-width:90px; height:auto;" />
  </a>
  <div class="media-body">
    <!-- citation -->
    
    <strong>Context-Aware Neural Machine Translation Learns Anaphora Resolution</strong><br />
    Elena Voita, Pavel Serdyukov, Rico Sennrich and Ivan Titov.
    
        In
        
          <i>Proceedings of ACL</i>,
        
      
    2018.
    
    <br />

    <!-- abstract -->
    
      <a data-toggle="modal" href="#abstractctx_anaphora.png" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractctx_anaphora.png" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Context-Aware Neural Machine Translation Learns Anaphora Resolution</h4>
            </div>
            <div class="modal-body">
              <p>Standard machine translation systems process sentences in isolation and hence ignore extra-sentential information, even though extended context can both prevent mistakes in ambiguous cases and improve translation coherence. We introduce a context-aware neural machine translation model designed in such way that the flow of information from the extended context to the translation model can be controlled and analyzed. We experiment with an English-Russian subtitles dataset, and observe that much of what is captured by our model deals with improving pronoun translation. We measure correspondences between induced attention distributions and coreference relations and observe that the model implicitly captures anaphora. It is consistent with gains for sentences where pronouns need to be gendered in translation. Beside improvements in anaphoric cases, the model also improves in overall BLEU, both over its context-agnostic version (+0.7) and over simple concatenation of the context and source sentences (+0.6).</p>

            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
    

    <!-- bibtex -->
    
      <!-- Modal -->
      <div class="modal fade" id="bibtexctx_anaphora.png" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Bibtex | Context-Aware Neural Machine Translation Learns Anaphora Resolution</h4>
            </div>
            <div class="modal-body">
              <pre>@InProceedings{P18-1117,
    author = 	"Voita, Elena
    and Serdyukov, Pavel
        and Sennrich, Rico
        and Titov, Ivan",
    title = 	"Context-Aware Neural Machine Translation Learns Anaphora Resolution",
    booktitle = 	"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = 	"2018",
    publisher = 	"Association for Computational Linguistics",
    pages = 	"1264--1274",
    location = 	"Melbourne, Australia",
    url = 	"http://aclweb.org/anthology/P18-1117"
}
</pre>
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
      <a data-toggle="modal" href="#bibtexctx_anaphora.png" class="label label-default">Bibtex</a>&nbsp;
    

    <!-- resources -->
    <!-- draft/slides/poster/talk -->

    
    
    
    <a href="//arxiv.org/abs/1805.10163" class="label label-info">arXiv</a>
    
    
    
    <a href="//anthology.aclweb.org/attachments/P/P18/P18-1117.Notes.pdf" class="label label-info">Appendix</a>
    

    

    

    

    <!-- code and data -->
    

    

    <!-- amendments -->

    
  </div>
</div>

<div class="media">
  <a class="pull-left thumbnail" href="//aclweb.org/anthology/W18-6307">
    <img src="/img/paper/" alt="" style="max-width:90px; height:auto;" />
  </a>
  <div class="media-body">
    <!-- citation -->
    
    <strong>A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation</strong><br />
    Mathias M{"u}ller, Annette Rios, Elena Voita and Rico Sennrich.
    
        In
        
          <i>Proceedings of WMT: Research Papers</i>,
        
      
    2018.
    
    <br />

    <!-- abstract -->
    
      <a data-toggle="modal" href="#abstract" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstract" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation</h4>
            </div>
            <div class="modal-body">
              <p>The translation of pronouns presents a special challenge to machine translation to this day, since it often requires context outside the current sentence. Recent work on models that have access to information across sentence boundaries has seen only moderate improvements in terms of automatic evaluation metrics such as BLEU. However, metrics that quantify the overall translation quality are ill-equipped to measure gains from additional context. We argue that a different kind of evaluation is needed to assess how well models translate inter-sentential phenomena such as pronouns. This paper therefore presents a test suite of contrastive translations focused specifically on the translation of pronouns. Furthermore, we perform experiments with several context-aware models. We show that, while gains in BLEU are moderate for those systems, they outperform baselines by a large margin in terms of accuracy on our contrastive test set. Our experiments also show the effectiveness of parameter tying for multi-encoder architectures.</p>

            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
    

    <!-- bibtex -->
    
      <!-- Modal -->
      <div class="modal fade" id="bibtex" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Bibtex | A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation</h4>
            </div>
            <div class="modal-body">
              <pre>@inproceedings{muller-etal-2018-large, title = "A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation", author = {M{\"u}ller, Mathias  and
  Rios, Annette  and
  Voita, Elena  and
  Sennrich, Rico},
booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers", month = oct, year = "2018", address = "Belgium, Brussels", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/W18-6307", pages = "61--72", }
</pre>
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
      <a data-toggle="modal" href="#bibtex" class="label label-default">Bibtex</a>&nbsp;
    

    <!-- resources -->
    <!-- draft/slides/poster/talk -->

    
    
    
    
    

    

    

    

    <!-- code and data -->
    

    

    <!-- amendments -->

    
  </div>
</div>


        </div>
      </div>
    </div>
  <footer class="text-center text-muted">
    <hr/>
    Last updated June 19, 2019.<br/>
    <!--Created with
    Based on the code of <a href="https://github.com/alopez/alopez.github.com">Adam Lopez</a>.
    <a href="http://git-scm.com/">git</a>,
    <a href="http://jekyllrb.com">jekyll</a>,
    <a href="http://getbootstrap.com/">bootstrap</a>,
    and <a href="http://www.vim.org/">vim</a>.<br/>
    Feel free to reuse the
    <a href="https://github.com/alopez/alopez.github.com">source code</a>.<br/>
    Mirrors: <a href="http://www.cs.jhu.edu/~alopez/">cs.jhu.edu</a>,
    <a href="http://alopez.github.io/">github.io</a>
    <br/><br/>-->
    </footer>
  </body>
</html>
